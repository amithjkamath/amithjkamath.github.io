<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://amithjkamath.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://amithjkamath.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-28T20:30:43+00:00</updated><id>https://amithjkamath.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Market need for Auto-Contouring Solutions</title><link href="https://amithjkamath.github.io/blog/2025/autocontour-need/" rel="alternate" type="text/html" title="Market need for Auto-Contouring Solutions"/><published>2025-01-15T00:00:00+00:00</published><updated>2025-01-15T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2025/autocontour-need</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2025/autocontour-need/"><![CDATA[<p>The not-so-random initial state of this text is courtesy <a href="https://scholarqa.allen.ai/">Ai2 Scholar QA</a>, and it has been reasonably cross-checked and improved by a human. This is a WIP (Work-In-Progress): this message will be removed once sufficient progress has been made.</p> <hr/> <p>Automated contouring in radiation oncology represents a transformative application of artificial intelligence (AI) and machine learning technologies to address one of the most time-consuming and critical aspects of radiation therapy planning. Contouring—the process of precisely delineating tumor targets and surrounding healthy tissues (organs at risk)—traditionally requires radiation oncologists to manually outline these structures on CT, MRI, or PET scans. This process typically consumes 2-4 hours per patient case and introduces significant variability between clinicians.</p> <p>Automated contouring leverages deep learning algorithms, particularly convolutional neural networks, to automatically identify and delineate anatomical structures and tumor volumes with increasing accuracy. These AI-powered solutions can reduce contouring time by up to 90% while maintaining or even improving delineation accuracy. Modern systems can identify dozens of anatomical structures across various body sites including head and neck, thorax, abdomen, and pelvis.</p> <p>The technology represents a paradigm shift in radiation oncology workflow, moving from a fully manual process to a computer-assisted or fully automated approach with human supervision. By standardizing contours, automated systems reduce inter-observer variability and help ensure treatment plans more consistently follow clinical guidelines and best practices. This advancement allows radiation oncology departments to increase throughput, standardize care, and potentially improve treatment outcomes while reducing clinician workload.</p> <h2 id="market-need-and-problem-statement">Market need and Problem Statement</h2> <p>The radiation oncology field faces a critical challenge in the contouring process, which represents a significant bottleneck in treatment planning workflow. Manual contouring—the traditional approach to delineating tumors and organs at risk—is exceptionally time-consuming, with studies showing it typically requires 2-4 hours per patient case. This labor-intensive process not only strains limited clinical resources but also delays treatment initiation, which can directly impact patient survival rates <a href="https://www.medrxiv.org/content/10.1101/2021.12.07.21266421v1">(Anand et al., 2021)</a>. Using an observational cohort study of 25 216 patients from the National Cancer Database, a survival benefit to a shorter time from surgery to the start of radiation (TS-RT) for patients with head and neck squamous cell carcinoma showed that a TS-RT of 42 days or less was associated with improved survival compared with 50 days or longer; a delay of 1 week resulted in inferior outcomes for patients with tonsil tumors.<a href="https://jamanetwork.com/journals/jamaotolaryngology/fullarticle/2674050">(Harris et al., 2018)</a>.</p> <p>A fundamental problem with manual contouring is the high degree of variability in results. Contouring outcomes vary significantly between clinicians (inter-observer variability) and even when performed by the same clinician at different times (intra-observer variability) <a href="https://www.semanticscholar.org/paper/Rapid-Automated-Target-Segmentation-and-Tracking-on-Chebrolu-Saenz/d63fad8e1a53c9ef3d4ae80a3923888e4587d213">(Chebrolu et al., 2014)</a><a href="https://pubmed.ncbi.nlm.nih.gov/38111502/">(Heilemann et al., 2023)</a>. This variability stems from differences in radiation oncology training, experience levels, and interpretation of imaging studies <a href="https://www.wjgnet.com/2644-3260/full/v2/i2/13.htm">(Yakar et al., 2021)</a>. Such inconsistencies can significantly impact dose/volume-based plan evaluation, clinical outcomes, and introduce bias in clinical trials <a href="https://pubmed.ncbi.nlm.nih.gov/38111502/">(Heilemann et al., 2023)</a><a href="https://pubmed.ncbi.nlm.nih.gov/26729432/">(Boero et al., 2016)</a>.</p> <p>The market need for automated contouring solutions is further amplified by the predicted substantial shortage of radiation oncologists in the United States, United Kingdom, and low/middle-income countries <a href="https://www.medrxiv.org/content/10.1101/2021.12.07.21266421v1">(Anand et al., 2021)</a>. This workforce shortage creates an urgent need for technologies that can improve efficiency without compromising quality. Research indicates that computer-assisted contouring methods can provide significant time savings—26-29% for experienced physicians and 38-47% for less experienced physicians <a href="https://www.semanticscholar.org/paper/Computer-assisted-framework-for-delineation-of-GTV-Ikushima-Arimura/a39faf0956858746ad557938bf1615c69ac51c5b">(Ikushima et al., 2017)</a><a href="https://www.sciencedirect.com/science/article/pii/S0360301607006931?via%3Dihub">(Chao et al., 2007)</a>.</p> <p>Beyond operational efficiency, the clinical impact of contouring quality is profound. The uncertainties in gross tumor volume (GTV) regions significantly impact the precision of entire radiation treatment courses <a href="https://www.semanticscholar.org/paper/Computer-assisted-framework-for-delineation-of-GTV-Ikushima-Arimura/a39faf0956858746ad557938bf1615c69ac51c5b">(Ikushima et al., 2017)</a>. This is particularly critical in advanced techniques like stereotactic body radiation therapy (SBRT), where precise targeting is essential for delivering higher doses to tumors while sparing surrounding normal tissue. Auto-segmentation addresses these challenges by providing faster, more consistent results that are less dependent on user experience (Doolan et al., 2023)(Sharp et al., 2014).</p> <p>A significant challenge in developing effective auto-segmentation solutions is the relative scarcity of curated multi-expert observer datasets sufficiently large to train machine learning models, particularly for complex anatomical areas like the head and neck that demonstrate high interobserver segmentation variability (Lin et al., 2022)(Mak et al., 2019). Despite these challenges, advancing auto-segmentation technologies offers tremendous potential for standardization across institutions and users, enabling improvements in both routine clinical practice and adaptive radiotherapy approaches (Segedin et al., 2016)<a href="https://pubmed.ncbi.nlm.nih.gov/38111502/">(Heilemann et al., 2023)</a>.</p>]]></content><author><name></name></author><category term="tairo,"/><category term="radiation-oncology,"/><category term="artificial-intelligence"/><summary type="html"><![CDATA[The not-so-random initial state of this text is courtesy Ai2 Scholar QA, and it has been reasonably cross-checked and improved by a human. This is a WIP (Work-In-Progress): this message will be removed once sufficient progress has been made.]]></summary></entry><entry><title type="html">Paper Summary: Deep learning in medical imaging and radiation therapy</title><link href="https://amithjkamath.github.io/blog/2024/deep-learning-in-radiation-therapy/" rel="alternate" type="text/html" title="Paper Summary: Deep learning in medical imaging and radiation therapy"/><published>2024-01-01T00:00:00+00:00</published><updated>2024-01-01T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2024/deep-learning-in-radiation-therapy</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2024/deep-learning-in-radiation-therapy/"><![CDATA[<h2 id="background-and-introduction">Background and Introduction</h2> <p>The success of DL compared to traditional machine learning methods is primarily based on two interrelated factors: depth and compositionality. A function is said to have a compact expression if it has few computational elements used to represent it (“few” here is a relative term that depends on the complexity of the function). An architecture with sufficient depth can produce a compact representation, whereas an insufficiently deep one may require an exponentially larger architecture (in terms of the number of computational elements that need to be learned) to represent the same function.</p> <p>A compact representation requires fewer training examples to tune the parameters and produces better generalization to unseen examples. This is critically important in complex tasks such as computer vision where each object class can exhibit many variations in appearance which would potentially require several examples per type of variation in the training set if a compact representation is not used.</p> <p>The second advantage of deep architectures has to do with how successive layers of the network can utilize the representations from previous layers to compose more complex representations that better capture critical characteristics of the input data and suppress the irrelevant variations (for instance, simple translations of an object in the image should result in the same classification). In image recognition, deep networks have been shown to capture simple information such as the presence or absence of edges at different locations and orientations in the first layer. Successive layers of the network assemble the edges into compound edges and corners of shapes, and then into more and more complex shapes that resemble object parts.</p> <p>Hierarchical representation learning is very useful in complicated tasks such as computer vision where adjacent pixels and object parts are correlated with each other and their relative locations provide clues about each class of object, or speech recognition and natural language processing where the sequence of words follow contextual and grammatical rules that can be learned from the data.</p> <h2 id="convolutional-neural-networks">Convolutional Neural Networks</h2> <p>The most successful and popular DL architecture in imaging is the convolutional neural network (CNN). Nearby pixels in an image are correlated with one another both in areas that exhibit local smoothness and areas consisting of structures (e.g., edges of objects or textured regions). These correlations typically manifest themselves in different parts of the same image. Accordingly, instead of having a fully connected network where every pixel is processed by a different weight, every location can be processed using the same set of weights to extract various repeating patterns across the entire image. These sets of trainable weights, referred to as kernels or filters, are applied to the image using a dot product or convolution and then processed by a nonlinearity (e.g., a sigmoid or tanh function). Each of these convolution layers can consist of many such filters resulting in the extraction of multiple sets of patterns at each layer.</p> <h2 id="as-applied-to-medical-imaging">As applied to Medical Imaging</h2> <p>In medical imaging, machine learning algorithms have been used for decades, starting with algorithms to analyze or help interpret radiographic images in the mid-1960s. Computer-aided detection/diagnosis (CAD) algorithms started to make advances in the mid 1980s, first with algorithms dedicated to cancer detection and diagnosis on chest radiographs and mammograms and then widening in scope to other modalities such as computed tomography (CT) and ultrasound. CAD algorithms in the early days predominantly used a data-driven approach as most DL algorithms do today. However, unlike most DL algorithms, most of these early CAD methods heavily depended on feature engineering.</p> <p>DL for radiological images, and shows a very strong trend: For example, in the first 3 months of 2018, more papers were published on this topic than the whole year of 2016.</p> <h2 id="image-segmentation-with-deep-learning">Image Segmentation with Deep Learning</h2> <p>Image segmentation in medical imaging based on DL generally uses two different input methods: (a) patches of an input image and (b) the entire image. Both methods generate an output map that provides the likelihood that a given region is part of the object being segmented. While patch-based segmentation methods were initially used, most recent studies use the entire input image to give contextual information and reduce redundant calculations.</p> <p>Lesion segmentation is a similar task to organ segmentation; however, lesion segmentation is generally more difficult than organ segmentation, as the object being segmented can have varying shapes and sizes.</p> <h2 id="dl-and-radiotherapy">DL and Radiotherapy</h2> <p>The goals of DL in radiation oncology are to assist in treatment planning, assess response to therapy, and provide automated adaptation in treatments over time. Deep reinforcement learning using both prior treatment plans and methods for assessing tumor local control was used to automatically estimate dose protocols. Such adaptive radiotherapy methods may provide clinical decision support for dose adaptation.</p> <p>Much of the needs in treatment planning relate to the segmentation of organs (discussed earlier) and in the prediction of dose distributions from contours. Nguyen et al used a U-net to predict dose from patient image contours on prostate intensity-modulated radiation therapy (IMRT) patients and demonstrated desired radiation dose distributions.</p> <p>While DL methods are being developed to plan and predict radiation therapy to specific tumor sites, they are also being investigated to assess toxicity to normal organs tissue.</p> <h2 id="more-to-read-from-here">More to read from here:</h2> <p>281: Zhen et al. used a transfer learning strategy to predict rectum dose toxicity for cervical cancer radiotherapy.</p> <p>283: Dose estimation was also the aim of Kajikawa et al. who investigated the feasibility of DL in the automated determination of dosimetric eligibility of prostate cancer patients undergoing intensity-modulated radiation therapy.</p> <p>218: Lao et al. investigated MRI radiomic features and DL as a means to predict survival in glioblastoma multiforme.</p> <h2 id="challenges-for-deep-learning-methods">Challenges for Deep Learning methods</h2> <p>Robustness is a challenge: Robustness and repeatability are concerns with any machine learning approach,365 and even more so with DL. Since medical image datasets are so difficult to come by compared to those of natural images and generally are of limited size, researchers like to reuse the same data for different tasks. Hence, correction for multiple comparisons is crucial in the statistical evaluation of performance. The requirement that datasets need to be of sufficient size and quality is not unique to DL or medical imaging.</p> <h2 id="references">References</h2> <p>Sahiner, B., Pezeshk, A., Hadjiiski, L. M., Wang, X., Drukker, K., Cha, K. H., Summers, R. M., &amp; Giger, M. L. (2019). Deep learning in medical imaging and radiation therapy. Medical Physics, 46(1), e1–e36.</p> <p><a href="https://doi.org/10.1002/mp.13264">Paper link on DOI</a></p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[Background and Introduction]]></summary></entry><entry><title type="html">Paper Summary: Quality Assurance for AI-Based Applications in Radiation Therapy</title><link href="https://amithjkamath.github.io/blog/2024/qa-for-ai-in-radiotherapy/" rel="alternate" type="text/html" title="Paper Summary: Quality Assurance for AI-Based Applications in Radiation Therapy"/><published>2024-01-01T00:00:00+00:00</published><updated>2024-01-01T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2024/qa-for-ai-in-radiotherapy</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2024/qa-for-ai-in-radiotherapy/"><![CDATA[<p>AI algorithms are typically data-driven, may be continuously evolving, and their behavior has a degree of (acceptable) uncertainty due to inherent noise in training data and the substantial number of parameters that are used in the algorithms.</p> <p>QA for AI-based systems is an emerging area, which has not been intensively explored and requires interactive collaborations between medical doctors, medical physics experts, and commercial/research AI institutions.</p> <p>Given their unique role as a bridge between the clinical environment and new technologies, medical physics experts are most likely the main frontiers to implementing these automated systems to improve efﬁciency, quality, standardization, and acceleration of the workﬂow leading to more safe and accurate radiation administration.</p> <p>It is, therefore, crucial to provide clear guidance for understanding and tackling the difﬁculties inherent in high-quality AI systems. This has been recognized by different societies in medical physics, which have recently published a detailed Checklist for AI in Medical Physics (CLAMP).</p> <p>Case-speciﬁc QA refers to all checks that verify the output of an AI-based application generated for each patient or machine.10 When QA results are satisfactory, the output can be used in the RT workﬂow. When the case-speciﬁc QA check fails, the output is subject to a second veriﬁcation. Depending on the application, the quality of the model’s output can be monitored in multiple ways. Currently, human supervision of the output, in combination with quantitative/qualitative measures, is seen as one of the most important tools. Automatic case-speciﬁc QA methods can be utilized to highlight divergent behavior. When too frequent failures are detected during case-specific QA, a routine QA is carried out to determine whether a recommissioning of the deployed model is needed.</p> <p>Routine QA is dedicated to the regular supervision of the AI model validity with the intention to monitor if the model’s output changes unexpectedly after clinical workﬂow changes (eg, software update, etc.). For this purpose, a periodical end-to-end performance should be completed on a reference test dataset. When routine QA tests do not meet expectations, a model re-commissioning may be necessary.</p> <h2 id="references">References</h2> <p>Claessens, M., Oria, C. S., Brouwer, C. L., Ziemer, B. P., Scholey, J. E., Lin, H., Witztum, A., Morin, O., Naqa, I. el, van Elmpt, W., &amp; Verellen, D. (2022). Quality Assurance for AI-Based Applications in Radiation Therapy. In Seminars in Radiation Oncology (Vol. 32, Issue 4, pp. 421–431). W.B. Saunders.</p> <p><a href="https://doi.org/10.1016/j.semradonc.2022.06.011">Paper link on DOI</a></p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[AI algorithms are typically data-driven, may be continuously evolving, and their behavior has a degree of (acceptable) uncertainty due to inherent noise in training data and the substantial number of parameters that are used in the algorithms.]]></summary></entry><entry><title type="html">About Us: “I would like to convert my research into a useful tool for clinicians.” - Center for Artificial Intelligence in Medicine (CAIM)</title><link href="https://amithjkamath.github.io/blog/2022/about-us-i-would-like-to-convert-my-research-into-a-useful-tool-for-clinicians-center-for-artificial-intelligence-in-medicine-caim/" rel="alternate" type="text/html" title="About Us: “I would like to convert my research into a useful tool for clinicians.” - Center for Artificial Intelligence in Medicine (CAIM)"/><published>2022-12-01T00:00:00+00:00</published><updated>2022-12-01T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2022/about-us-i-would-like-to-convert-my-research-into-a-useful-tool-for-clinicians---center-for-artificial-intelligence-in-medicine-caim</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2022/about-us-i-would-like-to-convert-my-research-into-a-useful-tool-for-clinicians-center-for-artificial-intelligence-in-medicine-caim/"><![CDATA[<p>December 2022Amith Kamath wishes to facilitate faster radiotherapy treatment for patients with glioblastoma through AI-supported therapy planning. The CAIM Young Researcher Award winner appreciates the openness of the Bernese community around AI applications in healthcare, also welcoming ideas from people trained in other disciplines to tackle hard problems in medicine. He is currently pursuing his PhD at the Medical Image Analysis research group of the ARTORG Center for Biomedical Engineering Research and looks forward to translating his research into a clinical tool through the broad entrepreneurial support he is receiving in Bern – including the personalized business coaching by be-advanced as part of his CAIM Award win in the category “translation”.What drives you in your research? My research is centered around evaluating the quality of radiotherapy delivered to patients with glioblastoma. Given the usually bad prognosis, people already diagnosed with this tumor currently must wait between one and three weeks until they can start treatment, due to the current workflows in radiotherapy planning. We expect that by using AI models to help draw boundaries around organs while simultaneously estimating the radiation dose and toxicity, radiotherapy treatment can be started earlier before the tumor has progressed further. We hope that someday our work can really add quality to people’s lives in this sense.The challenge in radiotherapy for glioblastoma is to be targeted while killing the tumor but sparing healthy areas of the brain. Mistakes made in these initial steps in the process can add up in subsequent steps, underscoring the importance of being precise. For example, if you irradiate healthy tissue in the brain, people can lose their functional abilities, for example speech or motor abilities. Our idea is to use deep neural networks to not only estimate, but also simulate inter-expert variations in boundaries that are drawn around tumors as well as healthy areas during radiotherapy planning. These simulations give us a better sense of the range of safe variations in how human experts manually do this and thereby understand the clinical impact of such variations in the process, leading to safer treatment.What does winning a CAIM Young Researcher Award mean to you? What matters to me most is that many of us were able to share our research and receive constructive feedback and comments in a setting like the CAIM Symposium. Beyond the award, the existence of such a vibrant community is very rewarding. For the translational focus of the award, I was fortunate to receive prior exposure through the Innosuisse startup toolbox program “Business Concepts” in October this year. The entrepreneurial coaching opportunity I now have with the CAIM Award is the perfect continuation of that. It would be great to get the experts’ opinion on how we can convert our research into a useful tool or product for clinicians!The unique thing here in Bern is the entrepreneurial support you receive, for example through the Swiss Institute for Translational and Entrepreneurial Medicine, sitem-insel. There is a lot of existing knowledge amongst the faculty about how a PhD project can be shaped into a product that can be used in clinics, which is quite exciting! If there are ten users of what I build, that will mean more to me than writing a long PhD thesis that no one may read.How important is it for you to share your research? Very much! My background is mostly in image processing and computer vision, and I think it’s great how welcoming the scientific community here is to researchers from other academic backgrounds. I don’t have a biomedicine background, and I believe people without medical schooling can make strong contributions to tackling hard problems in the medical space. Ways of thinking that are commonplace in another field could be novel to healthcare challenges and thus lead to innovative solutions. I like the people I get to work with daily who motivate me by asking all the right questions. I like that my work is very visual: I find it easier to look at a set of images or a video than at a bunch of equations for an “Aha” moment. When some images are hard to interpret, I appreciate that clinicians are quite open to talk to technical folks like us. This readiness to work with each other and speak the same language is quite important in this line of work. Therefore, I like to share our research with a broader global community. I use Social Media to exchange ideas with other scientists and our research lab Medical Image Analysis has started a “How to” video series for beginners in Deep Learning for medical imaging, summarizing some of the pitfalls and stumbling blocks in a humorous way (https://github.com/ubern-mia/bender). We are also currently preparing for a symposium on interpretability of AI models at CAIM in March ‘23, with the hope to get a lively discussion going on this important topic for safer AI adoption in medicine.Amith is a computer scientist and holds a Master of Science in Computer Science from Georgia Institute of Technology, in the US. He worked earlier as a software developer at the MathWorks Inc., on the Image Processing and Computer Vision Toolboxes in MATLAB, a scientific computing programming language. Prior to that, he earned a Master of Science in Electrical Engineering at University of Minnesota, and a Bachelor of Technology from National Institute of Technology Karnataka, in Surathkal, India. Currently, he is pursuing a PhD in Biomedical Engineering at the ARTORG Center at the University of Bern, under the supervision of Prof. Dr. Mauricio Reyes.His PhD thesis is on image segmentation and how one could use AI models to not only automate the otherwise time and effort intensive segmentation process, but further evaluate the quality of the contours in comparison to human-experts. His research focuses both on the robustness of using AI models to perform auto-segmentation, as well as computing radiotherapy dose predictions from these contours faster than current methods used in clinical practice. These results could help improve the speed as well as the quality and safety of radiotherapy plans for patients suffering from glioblastoma.Bern Interpretable AI Symposium (BIAS): www.caim.unibe.ch/bias2023</p>]]></content><author><name></name></author></entry><entry><title type="html">Paper Summary: Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations</title><link href="https://amithjkamath.github.io/blog/2022/Which-explanation-should-I-choose/" rel="alternate" type="text/html" title="Paper Summary: Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations"/><published>2022-11-16T00:00:00+00:00</published><updated>2022-11-16T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2022/Which-explanation-should-I-choose</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2022/Which-explanation-should-I-choose/"><![CDATA[<p>This paper …</p> <p>Major contributions of this work include: -</p> <h1 id="major-learning-points">Major Learning Points</h1> <ol> <li></li> <li></li> </ol> <h1 id="interesting-bits">Interesting bits</h1> <ol> <li></li> <li></li> </ol> <h2 id="references">References</h2> <p><a href="https://arxiv.org/abs/2206.01254">Paper link on Arxiv</a></p> <p>Paper code doesn’t appear to be released yet, although is mentioned in the appendix.</p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[This paper …]]></summary></entry><entry><title type="html">Paper Summary: Volumetric memory network for interactive medical image segmentation</title><link href="https://amithjkamath.github.io/blog/2022/Volumetric-memory-networks/" rel="alternate" type="text/html" title="Paper Summary: Volumetric memory network for interactive medical image segmentation"/><published>2022-11-03T00:00:00+00:00</published><updated>2022-11-03T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2022/Volumetric-memory-networks</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2022/Volumetric-memory-networks/"><![CDATA[<p>This paper …</p> <p>Major contributions of this work include: -</p> <h1 id="major-learning-points">Major Learning Points</h1> <ol> <li></li> <li></li> </ol> <h1 id="interesting-bits">Interesting bits</h1> <ol> <li></li> <li></li> </ol> <h2 id="references">References</h2> <p><a href="https://www.sciencedirect.com/science/article/pii/S1361841522002316">Paper link on Sciencedirect</a></p> <p><a href="https://github.com/lingorX/Mem3D">Paper code</a></p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[This paper …]]></summary></entry><entry><title type="html">Paper Summary: Calibrating Segmentation Networks with Margin Based Label Smoothing</title><link href="https://amithjkamath.github.io/blog/2022/Calibrating-segmentation-networks/" rel="alternate" type="text/html" title="Paper Summary: Calibrating Segmentation Networks with Margin Based Label Smoothing"/><published>2022-10-19T00:00:00+00:00</published><updated>2022-10-19T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2022/Calibrating-segmentation-networks</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2022/Calibrating-segmentation-networks/"><![CDATA[<p>This paper tackles the problem of models that are poorly calibrated, which result in over-confident predictions. The problem with cross entropy based loss functions is that it promotes the predicted softmax probabilities to match the one-hot label assignments, which means that the correct label activation should be significantly larger than the remaining activations.</p> <p>Major contributions of this work include: - A unifying constrained-optimization perspective of current state-of-the-art calibration losses, which are approximations of a linear penalty (or a Lagrangian term) imposing equality constraints on logit distances. - A simple and flexible generalization based on inequality constraints, which imposes a controllable margin on logit distances. - Comprehensive experiments on a variety of public medical image segmentation benchmarks demonstrate novel state-of-the-art results for calibration, while also improving the discriminative performance.</p> <h1 id="major-learning-points">Major Learning Points</h1> <ol> <li> <p>There are many existing methods of improving calibration, including focal loss and label smoothing. The authors show in this paper that these could be viewed as different penalty functions for imposing the same logit-distance equality constraint “d(l) = 0” (where d is the logit distance to the winning class). The proposed margin-based generalization (d(l) ≤ m) of this logit-distance constraint is shown to have desirable properties like gradient dynamics for calibrating neural networks.</p> </li> <li> <p>The experiments are rather comprehensive, however some of the data sets are really small. For example the MRBrainS18 data set has 7 subjects and 5 are used as training, 2 as test. The ACDC data set is split into 70 training, 10 validation and 20 test, which could have better power to make reasonable inferences. With this context, the results cannot hence be compared apples to apples (in my opinion at least) with each other, as BRATS (which has 4x the subjects as ACDC) should be equally highly weighted while evaluating the metrics.</p> </li> </ol> <h1 id="interesting-bits">Interesting bits</h1> <ol> <li> <p>The calibration performance metrics this paper uses include ECE (Expected Calibration Error) and CECE (Classwise ECE). These attempt to address the problem that pseudo-probability of the predicted class almost always over-estimates the actual probability of getting a correct answer. For example, if the largest pseudo-probability is 0.95 you don’t have a 95% chance of making a correct prediction — more like 75% or 85% chance of a correct prediction. (see <a href="https://jamesmccaffrey.wordpress.com/2021/01/22/how-to-calculate-expected-calibration-error-for-multi-class-classification/">here</a> for a great explanation of how ECE is computed).</p> </li> <li> <p>The networks chosen to test out this novel loss formulation to improve calibration include the now classic Unet, in addition to attention-Unet, Unet++, and TransUNet. What is interesting here is that the Unet somehow forms the basis of all subsequent networks and in spite of being nearly a decade old now, is still by far one of the best performing models.</p> </li> </ol> <h2 id="references">References</h2> <p><a href="https://arxiv.org/abs/2209.09641">Paper link on Arxiv</a></p> <p><a href="https://github.com/Bala93/MarginLoss">Paper code</a></p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[This paper tackles the problem of models that are poorly calibrated, which result in over-confident predictions. The problem with cross entropy based loss functions is that it promotes the predicted softmax probabilities to match the one-hot label assignments, which means that the correct label activation should be significantly larger than the remaining activations.]]></summary></entry><entry><title type="html">Paper Summary: Diffusion models beat GANs on Image Synthesis</title><link href="https://amithjkamath.github.io/blog/2022/Diffusion-models-beat-GANs/" rel="alternate" type="text/html" title="Paper Summary: Diffusion models beat GANs on Image Synthesis"/><published>2022-10-05T00:00:00+00:00</published><updated>2022-10-05T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2022/Diffusion-models-beat-GANs</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2022/Diffusion-models-beat-GANs/"><![CDATA[<p>This paper shows that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. This is achieved in unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, sample quality is improved with classifier guidance: compute-efficient method for trading off diversity for fidelity using gradients from a classifier (which is one of the advantages of GANs).</p> <p>Major contributions of this work include: - Introducing adaptive group normalization (AdaGN), which incorporates the timestep and class embedding into each residual block after a group normalization operation - Using classifier guidance, so that as few as 25 forward passes can generate samples maintaining FIDs (Frechet Inception Distance) comparable to BigGAN. - Architecture improvements: more heads or fewer channels per head improves FID; 64 channels is best for wall-clock time, hence 64 channels per head is used as default.</p> <h1 id="major-learning-points">Major Learning Points</h1> <ol> <li> <p>Diffusion models are a class of likelihood-based models which have recently been shown to produce high-quality images while offering desirable properties such as distribution coverage, a stationary training objective, and easy scalability. These models generate samples by gradually removing noise from a signal, and their training objective can be expressed as a reweighted variational lower-bound. It is hypothesized that the gap between diffusion models and GANs stems from at least two factors: first, that the model architectures used by recent GANs have been heavily explored and refined; second, that GANs are able to trade off diversity for fidelity, producing high quality samples but not covering the whole distribution.</p> </li> <li> <p>The proposed diffusion model obtains the best FID on each task, and the best sFID on all but one task (among LSUN and ImageNet data sets). With the improved architecture, state-of-the-art image generation results are obtained on LSUN and ImageNet 64×64. For higher resolution ImageNet, classifier guidance allows these models to substantially outperform the best GANs. These models obtain perceptual quality similar to GANs, while maintaining a higher coverage of the distribution as measured by recall, and can even do so using only 25 diffusion steps.</p> </li> </ol> <h1 id="interesting-bits">Interesting bits</h1> <ol> <li> <p>(from the Wikipedia entry) The Fréchet inception distance (FID) is a metric used to assess the quality of images created by a generative model, like a generative adversarial network (GAN). Unlike the earlier inception score (IS), which evaluates only the distribution of generated images, the FID compares the distribution of generated images with the distribution of a set of real images (“ground truth”). The FID metric was introduced in 2017, and is the current standard metric for assessing the quality of generative models as of 2020. It has been used to measure the quality of many recent models including the high-resolution StyleGAN1 and StyleGAN2 networks. Rather than directly comparing images pixel by pixel (for example, as done by the L2 norm), the FID compares the mean and standard deviation of the deepest layer in Inception v3. These layers are closer to output nodes that correspond to real-world objects such as a specific breed of dog or an airplane, and further from the shallow layers near the input image.</p> </li> <li> <p>Diffusion models are an extremely promising direction for generative modeling, but they are still slower than GANs at sampling (inference) time due to the use of multiple denoising steps (and therefore forward passes). Luhman and Luhman explore a way to distill the DDIM (Denoising Diffusion Implicit Models) sampling process into a single step model. The samples from the single step model are not yet competitive with GANs, but are much better than previous single-step likelihood-based models. Future work in this direction might be able to completely close the sampling speed gap between diffusion models and GANs without sacrificing image quality.</p> </li> </ol> <h2 id="references">References</h2> <p><a href="https://arxiv.org/abs/2105.05233">Paper link on Arxiv</a></p> <p><a href="https://github.com/openai/guided-diffusion">Paper code</a></p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[This paper shows that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. This is achieved in unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, sample quality is improved with classifier guidance: compute-efficient method for trading off diversity for fidelity using gradients from a classifier (which is one of the advantages of GANs).]]></summary></entry><entry><title type="html">Paper Summary: RadImageNet: An open radiologic deep learning research dataset for effective transfer learning</title><link href="https://amithjkamath.github.io/blog/2022/RadImageNet-open-radiologic-dataset/" rel="alternate" type="text/html" title="Paper Summary: RadImageNet: An open radiologic deep learning research dataset for effective transfer learning"/><published>2022-09-07T00:00:00+00:00</published><updated>2022-09-07T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2022/RadImageNet-open-radiologic-dataset</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2022/RadImageNet-open-radiologic-dataset/"><![CDATA[<p>This paper introduces a large scale dataset which demonstrates the value of pretraining with millions of radiologic images (within, or at least closer to the domain the eventual model is being trained on) compared with ImageNet photographic images (which could be quite a large semantic jump) on downstream medical applications when using transfer learning. They show that RadImageNet pretrained models could be an effective starting point for transfer learning in radiologic imaging artificial intelligence applications (where all the images are grayscale, for example).</p> <p>The main contributions of this work include:</p> <ul> <li>The RadImageNet database : a large-scale dataset consisting of 1.35 million radiologic images covering CT, MRI, and US modalities and 11 anatomic regions, annotated by fellowship-trained and board-certified radiologists.</li> <li>RadImageNet pretrained models show superior performance in the classification of eight independent medical applications as compared with ImageNet pretrained models, showing improvements from 0.9% to 9.4% for AuROC curve.</li> <li>RadImageNet pretrained models were also able to interpret results more consistently compared with ImageNet pretrained models in thyroid and breast applications, demonstrating Dice score gains of 64.6% and 16.4% in segmenting the lesions, respectively (these are significant improvements!).</li> </ul> <h1 id="major-learning-points">Major Learning Points</h1> <ol> <li> <p>The RadImageNet dataset was collected between January 2005 and January 2020 from 131872 patients at an outpatient radiology facility. This is a tremendous data curation effort spanning more than a decade, and it goes to show how important proper data curation and management is to building efficient models that learn what is actually meant to be learnt. 20 board-certified, fellowship- trained radiologists participated in the original clinical interpretation, who each had between 1 and 40 years of postfellowship experience. This also goes to show how much ‘knowledge transfer’ has to happen from well trained humans to such models via the dataset.</p> </li> <li> <p>This study was conducted in four phases:</p> <ul> <li>First, key images and associated diagnoses were annotated by radiologists.</li> <li>Second, the images and diagnoses were grouped by modalities, anatomic regions, and labels according to their imaging patterns to construct the medical imaging–only database.</li> <li>Third, four neural networks (Inception-ResNet-v2, ResNet50, DenseNet121, and InceptionV3) as pretrained models were trained from scratch based on RadImageNet and ImageNet (already existing in public domain).</li> <li>Finally, the pretrained models from RadImageNet and ImageNet were used and compared on eight medical imaging applications using AUC and Dice scores if ground truth segmentation masks were available.</li> </ul> </li> </ol> <h1 id="interesting-bits">Interesting bits</h1> <ol> <li> <p>All images were resized to 224 x 224 pixels and used as the inputs to these neural networks: I wonder if this is a good idea, as resizing without caring for the aspect ratio is one of the drawbacks in some sense of the ImageNet models. Now this may not impact classification models very much, but it should impact segmentation models.</p> </li> <li> <p>Each downstream application dataset was split into 75% training set, 10% validation set, and 15% test set. Images in one patient were always in the same set. Binary cross-entropy was selected as the loss function. The input images were downscaled to 256 x 256 pixels for the trade-off between accuracy and efficiency: the part about “images from one patient were always in the same set (training/val/test)” is a very important consideration that is unique to medical image analysis (can’t think of an analogy to general computer vision datasets), and is important that the authors have taken care of this.</p> </li> </ol> <h2 id="references">References</h2> <p><a href="https://pubs.rsna.org/doi/10.1148/ryai.210315">Paper link on RSNA</a></p> <p><a href="https://github.com/BMEII-AI/RadImageNet">Paper code</a></p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[This paper introduces a large scale dataset which demonstrates the value of pretraining with millions of radiologic images (within, or at least closer to the domain the eventual model is being trained on) compared with ImageNet photographic images (which could be quite a large semantic jump) on downstream medical applications when using transfer learning. They show that RadImageNet pretrained models could be an effective starting point for transfer learning in radiologic imaging artificial intelligence applications (where all the images are grayscale, for example).]]></summary></entry><entry><title type="html">Paper Summary: Interpretability-guided inductive bias for deep learning based medical image</title><link href="https://amithjkamath.github.io/blog/2022/Interpretability-guided-inductive-bias/" rel="alternate" type="text/html" title="Paper Summary: Interpretability-guided inductive bias for deep learning based medical image"/><published>2022-08-24T00:00:00+00:00</published><updated>2022-08-24T00:00:00+00:00</updated><id>https://amithjkamath.github.io/blog/2022/Interpretability-guided-inductive-bias</id><content type="html" xml:base="https://amithjkamath.github.io/blog/2022/Interpretability-guided-inductive-bias/"><![CDATA[<p>This paper proposes an interpretability-guided inductive bias approach (called SIBnet: salient inductive bias network) enforcing that learned features yield more distinctive and spatially consistent saliency maps for different class labels of trained models, leading to improved model performance. It is essential that trained models extract clinically relevant features for downstream tasks as, otherwise, shortcut learning and generalization issues can occur. In the medical field, trustability and transparency of current deep learning systems is a much desired property. These objectives are achieved by incorporating a class-distinctiveness loss and a spatial-consistency regularization loss term.</p> <p>The main contributions of this work include:</p> <ul> <li>Introduction of class distinctiveness and spatial coherence loss terms for saliency maps as part of the training process to improve interpretability while also improving model performance through better inductive bias.</li> <li>Extensive experiments comparing this loss formulation to existing state of the art methods like Convolutional Block Attention Module (CBAM) and Squeeze and Excitation models, showing marked improvement.</li> <li>A recipe for extending this formulation to the segmentation problem, where the encoder is used as is (where it is trained using the SIBnet loss), but the decoder is re-trained for the segmentation task.</li> </ul> <h1 id="major-learning-points">Major Learning Points</h1> <ol> <li> <p>“A trained radiologist learns to perform differential diagnosis on medical images based on disease-specific image patterns or characteristics. Consequently, during model training we propose to incorporate a novel inductive bias in the loss term of the model such that learned features yield more class-distinctive and spatially coherent interpretability saliency maps” - this is an interesting way to translate human intuition behind classifications to how a model should do it.</p> </li> <li> <p>In an attempt to quantify the models robustness to noise Gaussian noise of μ=0 and different σ ∈ {0.005,0.01,0.05,0.1} were added to input images. For the CheXpert dataset, the AUCROC values indicate that SIBNet performs more robustly to noise variations than others - and this is a good above-and-beyond example of ablation studies where robustness is explicitly tested for.</p> </li> </ol> <h1 id="interesting-bits">Interesting bits</h1> <ol> <li> <p>“Our study was limited to classification and segmentations tasks, and although we foresee interesting advantages, we cannot guarantee similar findings on tasks such localization and other regression tasks. We also limited our study to medical imaging datasets, but we see interesting applications to other medical multiomics scenarios” is a good disclaimer that one cannot be biased and go with the assumption that loss terms that work for classification adn segmentation may not work for other tasks. No undue bias here!</p> </li> <li> <p>It is interesting to observe the variety of metrics used here: Dice Coefficient (DC), Hausdorff Distance 95%(HD95), and Structural Similarity Index Measure (SSIM). To calculate these metrics, a binarized saliency map using the ConvexHull function of SciPy with default parameters was used. This detail to allow reproducibility (obviously with code shared as well) is a good practice to emulate.</p> </li> </ol> <h2 id="references">References</h2> <p><a href="https://pubmed.ncbi.nlm.nih.gov/35932546/">Paper link on PubMed</a></p>]]></content><author><name></name></author><category term="paper-summary,"/><category term="computer-vision"/><summary type="html"><![CDATA[This paper proposes an interpretability-guided inductive bias approach (called SIBnet: salient inductive bias network) enforcing that learned features yield more distinctive and spatially consistent saliency maps for different class labels of trained models, leading to improved model performance. It is essential that trained models extract clinically relevant features for downstream tasks as, otherwise, shortcut learning and generalization issues can occur. In the medical field, trustability and transparency of current deep learning systems is a much desired property. These objectives are achieved by incorporating a class-distinctiveness loss and a spatial-consistency regularization loss term.]]></summary></entry></feed>