<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Summary: Patches are all you need | Amith J. Kamath </title> <meta name="author" content="Amith J. Kamath"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://amithjkamath.github.io/blog/2021/patches-are-all-you-need/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Amith</span> J. Kamath </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Notes </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">Publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/teaching/">Teaching</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/glossary/">Glossary</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Summary: Patches are all you need</h1> <p class="post-meta"> Created on November 03, 2021 </p> <p class="post-tags"> <a href="/blog/2021"> <i class="fa-solid fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/category/paper-summary"> <i class="fa-solid fa-tag fa-sm"></i> paper-summary,</a>   <a href="/blog/category/computer-vision"> <i class="fa-solid fa-tag fa-sm"></i> computer-vision,</a>   <a href="/blog/category/transformers"> <i class="fa-solid fa-tag fa-sm"></i> transformers,</a>   <a href="/blog/category/mia"> <i class="fa-solid fa-tag fa-sm"></i> mia</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>The general claim here is that re-casting inputs into patches can inherently improve network performance.</p> <h1 id="major-learning-points">Major Learning Points</h1> <p>Deep Learning models based on the Transformer family of architectures have now gained more relevance in the Vision space (in addition to their predominance in the Text/time-series space). This means that images now need to be tokenized in some way - in the form of patches, to avoid quadratic runtime. The central question of this paper is then - is the accuracy gains due to the choice of architecture, or, due to re-casting the inputs as patches? Their experiments and results appear to support the latter - and they show an implementation called the ‘ConvMixer’ which seems to outperform Vision Transformers, as well as classical models like ResNet on the ImageNet top 1% task.</p> <p>This ConvMixer model is simple - creating patch embeddings, followed by repeated fully convolutional blocks. The first step is to generate patch embeddings, described as:</p> <p><code class="language-plaintext highlighter-rouge">z0 = batch_norm(non_linear{conv(X, stride=p, kernel_size=p)})</code></p> <p>where <code class="language-plaintext highlighter-rouge">p</code> is the patch size parameter (set to 7). Next comes the ConvMixer layers itself - which is repeated multiple times - in their experiments, 20 or 32 times (while still having few parameters, compared to ResNets, for example).</p> <p><code class="language-plaintext highlighter-rouge">zl′ = BN (σ{ConvDepthwise(zl−1)}) + zl−1</code></p> <p><code class="language-plaintext highlighter-rouge">zl+1 = BN (σ{ConvPointwise(zl′)})</code></p> <p>ConvDepthwise is a grouped convolution with number of groups equal to number of channels, and ConvPointwise is a 1x1 convolution. The kernel size for depthwise convolutions are unusually large - 7, 9 and even 15.</p> <p>These layers (and blocks of them when repeated) are followed by a global pooling, and then a softmax classifier.</p> <p>The name ConvMixer comes from the general class of models called MLPMixer. They use depth convolution to mix spatial locations and pointwise convolution to mix channel locations to generate arbitrarily large receptive fields. A more general term introduced is “Isotropic architecture”, where after patches are generated, shape and size of activations remain constant through the network.</p> <p>What is unique about their contribution is that it is fully convolutional (and hence have no Transformer-like layers) - supporting their claim that patches may be all one needs!</p> <h1 id="interesting-bits">Interesting bits</h1> <ul> <li>This is the only paper I’ve read where the appendix is longer than the text of the actual paper. This goes to show how simple the idea is, but how extensive the experiments are. This comes up in the review as well, and has been addressed by the authors with “thus hopefully demonstrate that some conference-level ML research can be communicated effectively via short papers”. This is commendable!</li> <li>The last page includes a punchy challenge - build a model with an implementation length in code that fits into a tweet, while also achieving 80% top-1 accuracy on the ImageNet dataset. I wonder what the motivation for these goals are - terse implementations do not help either the reader or the developer. It is indeed an impressive way to convey the simplicity of the idea.</li> <li>What isn’t really focused on is the throughout runtime performance. To the previous point, an even more ambitious goal could be to have the model representable in a tweet, have greater than 80% accuracy, and also, have throughput that matches SoTA. This trifecta is probably the hardest to optimize for.</li> <li>The training times were mindblowing as well - 10x-RTX 8000s took 9 days to train for 150 epochs. Although they do mention no hyperparameter optimization - most research groups won’t have such infrastructure for experiments, as far as I can say. Would be interesting to know the energy consumption for training such models too!</li> </ul> <h2 id="references">References</h2> <p><a href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="external nofollow noopener" target="_blank">Patches are all you need on Open Review</a></p> <p><a href="https://github.com/tmp-iclr/convmixer" rel="external nofollow noopener" target="_blank">GitHub implementation with an anonymized username</a></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://www.caim.unibe.ch/about_us/people/interviews/amith_kamath/index_eng.html" target="_blank" rel="external nofollow noopener">About Us: "I would like to convert my research into a useful tool for clinicians." - Center for Artificial Intelligence in Medicine (CAIM)</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/qa-for-ai-in-radiotherapy/">Paper Summary: Quality Assurance for AI-Based Applications in Radiation Therapy</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/deep-learning-in-radiation-therapy/">Paper Summary: Deep learning in medical imaging and radiation therapy</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Which-explanation-should-I-choose/">Paper Summary: Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Volumetric-memory-networks/">Paper Summary: Volumetric memory network for interactive medical image segmentation</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Amith J. Kamath. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: April 30, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>